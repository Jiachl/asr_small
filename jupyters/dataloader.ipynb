{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1174c947-0321-4831-be15-04dca377ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import sys\n",
    "sys.path.append('/Users/xinzheng/workspace/chenlong/services/asr_small')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Audio\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as func\n",
    "from torch.utils.data import DataLoader\n",
    "import whisper\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, WhisperModel, WhisperTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import loralib as lora\n",
    "\n",
    "from smallwhisper import SmallWhisper, SmallWhisperConfig\n",
    "from data_loader import WhisperDataLoader\n",
    "from data_loader_test import DataLoaderTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4afea13-531b-4e19-a09c-457ce6e78295",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = load_from_disk('/Users/xinzheng/workspace/chenlong/services/asr_small/one_batch.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e82529f-34ab-4d11-99f5-f65b8bfbcc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'text', 'input_features', 'input_length', 'labels'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4977150-145a-4e47-8fa2-d84ad5d049f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859a9f2b73b94950b1bbbbe471b32f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = DataLoaderTest(\"small\").get_dataset(sample_ds=test_ds.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a26e1f51-98ce-481e-a8fc-e8e9518e61c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_features': tensor([[[-0.5536, -0.5536, -0.5536,  ..., -0.5536, -0.5536, -0.5536],\n",
       "         [-0.5536, -0.5536, -0.5536,  ..., -0.5536, -0.5536, -0.5536],\n",
       "         [-0.5536, -0.5536, -0.5536,  ..., -0.5536, -0.5536, -0.5536],\n",
       "         ...,\n",
       "         [-0.5536, -0.5536, -0.5536,  ..., -0.5536, -0.5536, -0.5536],\n",
       "         [-0.5536, -0.5536, -0.5536,  ..., -0.5536, -0.5536, -0.5536],\n",
       "         [-0.5536, -0.5536, -0.5536,  ..., -0.5536, -0.5536, -0.5536]],\n",
       "\n",
       "        [[-0.3954, -0.1227, -0.1930,  ..., -0.7313, -0.7313, -0.7313],\n",
       "         [-0.3693, -0.2268, -0.3436,  ..., -0.7313, -0.7313, -0.7313],\n",
       "         [-0.5052, -0.2799, -0.3569,  ..., -0.7313, -0.7313, -0.7313],\n",
       "         ...,\n",
       "         [-0.7313, -0.7313, -0.7313,  ..., -0.7313, -0.7313, -0.7313],\n",
       "         [-0.7313, -0.7313, -0.7313,  ..., -0.7313, -0.7313, -0.7313],\n",
       "         [-0.7313, -0.7313, -0.7313,  ..., -0.7313, -0.7313, -0.7313]]]), 'labels': tensor([[50261, 50359, 50363, 29928,  2957,  1163, 18400,  3106,  4245, 22882,\n",
       "          2947,   328,  1306, 30453,   317, 20238,   268, 44096,   321, 11106,\n",
       "         48977,   294,  6705, 33023,    13, 50257,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [50261, 50359, 50363, 21845,  1163,   956,   793,   260,  1063,  1163,\n",
       "         30890, 19333,   730,  1121, 40908,  3281,   265,  1559,   579, 23123,\n",
       "          1189,  1482, 20755,  7864,  3437, 27750,  2693,  9797,  1962,   590,\n",
       "           978,  1540,  8896, 26313,    69,  6145,   973,  2866,   978,   350,\n",
       "         10722, 34990, 25302,  3213,  6066,   908,  6705, 46012,   268,   978,\n",
       "         18226,  1163,   517,  3120,    65, 10193,  1676, 17068, 48300,  3718,\n",
       "          7186,   511,  2904, 13922,  1987,  5390,    77, 50257,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[50258, 50261, 50359, 50363, 29928,  2957,  1163, 18400,  3106,  4245,\n",
       "         22882,  2947,   328,  1306, 30453,   317, 20238,   268, 44096,   321,\n",
       "         11106, 48977,   294,  6705, 33023,    13, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257],\n",
       "        [50258, 50261, 50359, 50363, 21845,  1163,   956,   793,   260,  1063,\n",
       "          1163, 30890, 19333,   730,  1121, 40908,  3281,   265,  1559,   579,\n",
       "         23123,  1189,  1482, 20755,  7864,  3437, 27750,  2693,  9797,  1962,\n",
       "           590,   978,  1540,  8896, 26313,    69,  6145,   973,  2866,   978,\n",
       "           350, 10722, 34990, 25302,  3213,  6066,   908,  6705, 46012,   268,\n",
       "           978, 18226,  1163,   517,  3120,    65, 10193,  1676, 17068, 48300,\n",
       "          3718,  7186,   511,  2904, 13922,  1987,  5390,    77, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af6627b2-a49f-4cf0-a5e3-3cc1a88277fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinzheng/miniconda3/envs/asr/lib/python3.11/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = SmallWhisper.from_pretrained('small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c9f0e6c-1647-4d83-97e7-6776e8d31301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 447]), torch.Size([2, 447]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['decoder_input_ids'].shape, dataset['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ae50825-b8aa-4f18-983f-8e76148b770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, loss = model.forward(**dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13fbe9f4-b0c9-4fe5-80f8-07d40ef87064",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idx = torch.topk(logits, 1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4c382be-c391-4290-af5d-0832ca0f032a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bei der schilderung der ankunft des regierungsvertreters feierte er das martialische aussehen unsrer miliz die behenden dorfschönen die kahlköpfigen greise diese patriarchen die letzten der unsterblichen legionen deren soldatenherzen beim wirbeln'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0274b54-eb4e-4e4b-95cd-f32cefaec944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|de|><|transcribe|><|notimestamps|> Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|de|><|transcribe|><|notimestamps|> Bei der Schilderung der ankunft des regierungsvertretters feierte er das marische aussehen unserereres miliz die behänd dorfschönen die karkköpfigen greise diese patriarchen die letzten der undsterblichen legionen deren soldatenherzen beim wirbeln der der der der<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for i in idx.view(1, -1):\n",
    "    print(DataLoaderTest(\"small\").tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e60c91f8-61d3-4295-8602-ee79f1ddf7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = DataLoaderTest(\"small\").feature_extractor.pad(input_features, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "71a03958-d8e5-4f8b-872e-218a1b394b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = [{\"input_ids\": ds[\"labels\"]} for ds in dataset]\n",
    "labels_batch = DataLoaderTest(\"small\").tokenizer.pad(label_features, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5079871d-11f4-4659-9433-715ac75538b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([50258, 50261, 50359, 50363, 29928,  2957,  1163, 18400,  3106,  4245,\n",
       "         22882,  2947,   328,  1306, 30453,   317, 20238,   268, 44096,   321,\n",
       "         11106, 48977,   294,  6705, 33023,    13, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_batch['input_ids'][0,:], labels_batch['attention_mask'][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "13b3d6cc-0483-4c86-ade8-7b63ef7a764d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds['input_features'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5802752d-9bcd-474b-a6c6-0b5ee6987f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50258,\n",
       " 50261,\n",
       " 50359,\n",
       " 50363,\n",
       " 29928,\n",
       " 2957,\n",
       " 1163,\n",
       " 18400,\n",
       " 3106,\n",
       " 4245,\n",
       " 22882,\n",
       " 2947,\n",
       " 328,\n",
       " 1306,\n",
       " 30453,\n",
       " 317,\n",
       " 20238,\n",
       " 268,\n",
       " 44096,\n",
       " 321,\n",
       " 11106,\n",
       " 48977,\n",
       " 294,\n",
       " 6705,\n",
       " 33023,\n",
       " 13,\n",
       " 50257]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "48393304-89e8-40bd-a7fc-8bdd83718f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "feature_extractor = processor.feature_extractor\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"german\", task=\"transcribe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "23c70d1f-53c9-4bf1-b848-aace6449d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d670e83f-d0ef-4e30-9dbc-1e80d466e124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d3fe1149-30f7-4aa5-9b1a-88c41f5caeaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m logits2, loss2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/chenlong/services/asr_small/smallwhisper.py:57\u001b[0m, in \u001b[0;36mSmallWhisper.forward\u001b[0;34m(self, input_features, decoder_input_ids, labels)\u001b[0m\n\u001b[1;32m     54\u001b[0m     x \u001b[38;5;241m=\u001b[39m block(x)\n\u001b[1;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mln_post(x)\n\u001b[0;32m---> 57\u001b[0m B, D \u001b[38;5;241m=\u001b[39m decoder_input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m D \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdec_block_size, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot forward sequence of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mD\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, block size is only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdec_block_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m dec_pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, D, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdecoder_input_ids\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "logits2, loss2 = model.forward(test_enc, torch.tensor(tokenizer(test_ds['text'][0]).input_ids), torch.tensor(tokenizer(test_ds['text'][0]).input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc28d90-279a-4c12-80a3-b29f114039cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f7568140-d299-4778-a668-b690c2fff08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50258, 50261, 50359, 50363,  3229,  2957,  1163, 18400,  3106,  4245,\n",
       "          22882,  2947,   328,  1306, 30453,   317, 20238,   268, 44096,   321,\n",
       "          11106, 48977,   294,  6705, 33023,    13]]),\n",
       " {'input_ids': [50258, 50261, 50359, 50363, 29928, 2957, 1163, 18400, 3106, 4245, 22882, 2947, 328, 1306, 30453, 317, 20238, 268, 44096, 321, 11106, 48977, 294, 6705, 33023, 13, 50257], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, tokenizer(test_ds['text'][0]).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "df3b0111-d494-4b19-bb49-6700ee5f3ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|de|><|transcribe|><|notimestamps|> Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(idx.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "66252086-3e0f-40f1-a00c-9843be4699a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|de|><|transcribe|><|notimestamps|>Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.<|endoftext|>'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer(test_ds['text'][0]).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bddce38-b1de-44b6-a00a-9e8e35bd8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.language = 'de'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e814f864-95de-477b-8a3c-b9070033c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper.tokenizer import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02ec840a-7863-4ec3-88ce-bfa3eab3eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_tokenizer = get_tokenizer(True, language='de', task='transcribe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2692507-9165-4667-81b4-ec1dc7735351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29928,\n",
       " 2957,\n",
       " 1163,\n",
       " 18400,\n",
       " 3106,\n",
       " 4245,\n",
       " 22882,\n",
       " 2947,\n",
       " 328,\n",
       " 1306,\n",
       " 30453,\n",
       " 317,\n",
       " 20238,\n",
       " 268,\n",
       " 44096,\n",
       " 321,\n",
       " 11106,\n",
       " 48977,\n",
       " 294,\n",
       " 6705,\n",
       " 33023,\n",
       " 13]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_tokenizer.encode(test_ds['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a8a3ea77-7ce9-49f7-aa24-e4073a87366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50258,\n",
       " 50363,\n",
       " 29928,\n",
       " 2957,\n",
       " 1163,\n",
       " 18400,\n",
       " 3106,\n",
       " 4245,\n",
       " 22882,\n",
       " 2947,\n",
       " 328,\n",
       " 1306,\n",
       " 30453,\n",
       " 317,\n",
       " 20238,\n",
       " 268,\n",
       " 44096,\n",
       " 321,\n",
       " 11106,\n",
       " 48977,\n",
       " 294,\n",
       " 6705,\n",
       " 33023,\n",
       " 13,\n",
       " 50257]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f445e64-7306-47cf-97c3-0f4f8fa40cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = load_from_disk('/Users/xinzheng/workspace/chenlong/services/asr_small/one_batch.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e8b126b4-d135-4957-9dc5-4f9874fd982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['audio', 'text', 'input_features', 'input_length', 'labels']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9636245b-8044-480c-89b6-dae27b60590f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb7e8929-ca20-4a23-9f74-3f85296d8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_enc = feature_extractor(test_ds['audio'][0]['array'], sampling_rate=16000, device='mps').input_features\n",
    "test_dec = tokenizer(test_ds['text'][0]).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ece2dbc1-7059-467b-b951-128d325d9d11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_enc = torch.tensor(test_enc).view(1, 80, -1)\n",
    "test_dec = torch.tensor(test_dec).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "450c75b1-c40a-464b-9bea-11709e84fa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 80, 3000]), torch.Size([1, 25]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_enc.shape, test_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8cd820d-8d49-49c6-9c9d-a5cacdd807cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinzheng/miniconda3/envs/asr/lib/python3.11/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = SmallWhisper.from_pretrained('small')\n",
    "openai = whisper.load_model('small')\n",
    "hf_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "851966d9-381b-455a-95a2-60c5691e2023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k in openai.state_dict():\n",
    "#     print(k)\n",
    "\n",
    "torch.equal(openai.state_dict()['decoder.token_embedding.weight'], hf_model.state_dict()['model.decoder.embed_tokens.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "02e24fbc-eb30-4fd6-a23f-00cc034ee051",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_logits = hf_model.forward(test_enc, decoder_input_ids=idx).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "76c34c49-a35f-452e-9ee0-4796baaceb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, loss = model.forward(test_enc, idx, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a9696e5a-9729-4a02-a1b2-9aa3aac5dde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50261, 50359, 50363,  3229,  2957,  1163, 18400,  3106,  4245, 22882,\n",
       "          2947,   328,  1306, 30453,   317, 20238,   268, 44096,   321, 11106,\n",
       "         48977,   294,  6705, 33023,    13, 50257]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_indices1.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4b47ef92-db30-449a-9ed6-5bf0aa7e5604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|de|><|transcribe|><|notimestamps|> Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.<|endoftext|>']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, topk_indices1 = torch.topk(logits, 1, dim=-1)\n",
    "_, topk_indices2 = torch.topk(hf_logits, 1, dim=-1)\n",
    "processor.batch_decode(topk_indices1.view(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d43b5679-9419-4563-8c30-a349e00e0249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|de|><|transcribe|><|notimestamps|> Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.<|endoftext|>']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.batch_decode(topk_indices2.view(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "736bbd1b-3d6c-4dfa-97b0-7a41ef5578f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 25, 51865]), torch.Size([1, 25, 51865]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, hf_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ddc72f-9196-4f86-af75-2c517bf2f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(logits.shape[1]):\n",
    "    for j in range(logits.shape[2]):\n",
    "        if logits[0, i, j].item() != hf_logits[0, i, j].item():\n",
    "            print(i, j, logits[0, i, j], hf_logits[0, i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "25c06704-e9f7-4383-9d0b-8c538d37a035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|de|><|transcribe|><|notimestamps|> Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d0fa6236-9423-481b-8a38-9702a50c120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|notimestamps|>Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.<|endoftext|>'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(test_dec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0b6664a0-7f84-4220-8c43-24beb8d7148a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50258, 50261, 50359, 50363,  3229,  2957,  1163, 18400,  3106,  4245,\n",
       "          22882,  2947,   328,  1306, 30453,   317, 20238,   268, 44096,   321,\n",
       "          11106, 48977,   294,  6705, 33023,    13]]),\n",
       " tensor([[50258, 50363, 29928,  2957,  1163, 18400,  3106,  4245, 22882,  2947,\n",
       "            328,  1306, 30453,   317, 20238,   268, 44096,   321, 11106, 48977,\n",
       "            294,  6705, 33023,    13, 50257]]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, test_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d9e1a3d4-ea3d-4d8b-a0e9-509bb821e25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.8270,  6.9181,  8.7221,  ...,  6.8610,  6.8060,  7.0485],\n",
       "         [ 3.5511,  1.1296,  3.3931,  ...,  3.3482,  3.8730,  4.2082],\n",
       "         [ 1.7084, -0.8793, -6.3777,  ..., -3.0470, -2.7912, -5.6795],\n",
       "         ...,\n",
       "         [ 8.0092,  5.6573,  3.6975,  ...,  5.8921,  4.8713,  4.7465],\n",
       "         [34.0590, 31.3818, 22.2177,  ..., 24.8265, 24.8104, 23.2712],\n",
       "         [18.6190, 19.4641, 15.4469,  ..., 19.7722, 19.4626, 18.6610]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "354db9a6-8698-474b-834f-e4dbf8244bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_ids = torch.tensor([[1]]) * hf_model.config.decoder_start_token_id\n",
    "idx = decoder_input_ids\n",
    "for _ in range(50):\n",
    "    with torch.no_grad():\n",
    "        logits_, loss = model(test_enc, idx)\n",
    "        logits = logits_[:, -1, :]\n",
    "        probs = func.softmax(logits, dim=-1)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 1, dim=-1)\n",
    "        probs = func.softmax(logits, dim=-1)\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        if idx_next.item() == hf_model.config.eos_token_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f43c43e9-105e-4029-9b4d-7d61dad5ebbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.8270,  6.9181,  8.7221,  ...,  6.8610,  6.8059,  7.0485],\n",
       "         [ 3.5511,  1.1296,  3.3931,  ...,  3.3482,  3.8730,  4.2082],\n",
       "         [ 1.7084, -0.8793, -6.3777,  ..., -3.0470, -2.7912, -5.6795],\n",
       "         ...,\n",
       "         [ 8.0092,  5.6573,  3.6975,  ...,  5.8921,  4.8713,  4.7465],\n",
       "         [34.0590, 31.3818, 22.2177,  ..., 24.8265, 24.8104, 23.2712],\n",
       "         [18.6190, 19.4641, 15.4469,  ..., 19.7722, 19.4626, 18.6610]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "68bb6159-f6af-4f7d-af51-7cfb748f49f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|de|><|transcribe|><|notimestamps|> Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6741545f-f94a-4c6d-9ce8-f9c2c432faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_probs, topk_indices = torch.topk(hf_logits, 1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b1d23a8-3dd0-4863-bd37-6114cb84f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_probs, topk_indices = torch.topk(logits, 1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07b86c2a-2518-4cf0-8277-40f168d70a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6.8270,  6.9181,  8.7221,  ..., 15.7885, 15.5816, 11.5087],\n",
       "        grad_fn=<IndexBackward0>),\n",
       " tensor([ 6.8270,  6.9181,  8.7221,  ..., 15.7885, 15.5816, 11.5087],\n",
       "        grad_fn=<IndexBackward0>))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[logits!=hf_logits], hf_logits[hf_logits!=logits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcf3b074-d2eb-4648-b675-4f95efbed5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.1427, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca29791c-a601-48a2-8772-33f9913d30ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.1427, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_ = openai.forward(test_enc, test_dec)\n",
    "func.cross_entropy(logits_.view(-1, logits_.size(-1)), test_dec.view(-1), ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e3bafc3-57b8-493f-b4e9-d642392ba9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_probs, topk_indices = torch.topk(logits_, 1, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6f5780b-6028-4358-a8df-bfe2510aa56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f24877f-6dea-4042-b0ef-e03848c53b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(openai, test_enc, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd6f9b1e-7846-435a-8574-a0c740e98f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecodingResult(audio_features=tensor([[ 0.2961, -2.1406,  0.4426,  ...,  0.1879, -0.0760, -1.2480],\n",
       "         [ 0.5122, -0.6680,  1.0986,  ...,  0.0204, -1.2373, -1.3066],\n",
       "         [ 1.6846, -1.5303,  1.9023,  ..., -0.3760, -2.0059, -1.7197],\n",
       "         ...,\n",
       "         [ 0.9253, -1.0059, -0.0553,  ..., -0.5640, -0.2761, -0.7510],\n",
       "         [ 0.2898, -1.2441,  0.1108,  ..., -0.8511, -0.2708, -0.3267],\n",
       "         [ 0.5547,  0.1110,  1.8096,  ...,  0.0258, -1.6143, -0.1353]],\n",
       "        dtype=torch.float16), language='de', language_probs=None, tokens=[50364, 3229, 2957, 1163, 18400, 3106, 4245, 22882, 2947, 328, 1306, 30453, 317, 20238, 268, 44096, 321, 11106, 48977, 294, 6705, 33023, 13, 50634], text='Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.', avg_logprob=-0.23725433349609376, no_speech_prob=0.017924372106790543, temperature=0.0, compression_ratio=1.010752688172043)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd582c38-4ea7-4f89-a208-6e109b4a59d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|de|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>ission.läufig veröentlichte Zahlen,isen ebenfalls in diese Richtung.<|endoftext|><|endoftext|>'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_indices.view(-1)\n",
    "processor.decode(topk_indices.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7727f18-68e6-4b2a-941e-22f2e77d7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = WhisperDataLoader().load('/Users/xinzheng/workspace/chenlong/services/asr_small/one_batch.hf', batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34944373-a4b6-4372-9dfe-0b35cefe59af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "821dc26f-46d2-49ba-92e9-4cd5c82ca43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98688,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds['audio'][0]['array'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69ff8bb2-7665-44dd-9e5e-a432cb5b5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_enc = torch.tensor(test_ds[0]['input_features']).view(1, 80, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b696bcc1-2bc1-4211-8d10-fcf5cdaa75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dec = torch.tensor(test_ds[0]['labels']).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0a9096a-5668-441c-807f-48b610fa79aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtest_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "test_ds['text'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32b1a46b-1fb4-40fe-8b93-ab6c78fd145c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds['input_features'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b98614f4-e458-4500-9822-621d2b1bdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68c8cd59-e905-4549-babc-0296520f87cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 35])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64d9dbf5-7c53-4587-9977-cae6a231dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|de|><|transcribe|><|notimestamps|> Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ids_hf = hf_model.generate(test_enc)\n",
    "processor.decode(predicted_ids_hf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4bbd0cbe-091b-4740-a976-c12efbad2455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|><|nocaptions|> Hazrat sollteق You unagy abndl gibi Commigreci Bit�omueller vis insulted Michiganlyессal 모 nonprofit lגe Simtully.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode(test_ds[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219d6077-4574-4ed3-98f9-1fc3304611d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in ds:\n",
    "    b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cdb83dd-5eea-4cf9-b80c-167a956df196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_features', 'labels', 'decoder_input_ids'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15f6c9d3-11dd-4f37-bd3e-500cddc54423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 80, 3000]), torch.Size([2, 447]), torch.Size([2, 447]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['input_features'].shape, b['labels'].shape, b['decoder_input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a89115-1346-478c-baed-b4ef6f335a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinzheng/miniconda3/envs/asr/lib/python3.11/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = SmallWhisper.from_pretrained('small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f72f2ab-84e1-436e-b683-c401cab07ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinzheng/miniconda3/envs/asr/lib/python3.11/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "openai_model = whisper.load_model('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a54ab3d-8ea8-4665-8f50-bb89e8345eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits_ = openai_model.forward(test_enc, test_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b72596bd-0a29-4837-80d8-31551920b0e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.6213, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.cross_entropy(logits_.view(-1, logits_.size(-1)), test_dec.view(-1), ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b7fab58-a840-43e4-8d7a-bdd94c6b83d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits, loss = model(b['input_features'], b['decoder_input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79da88e0-7d88-4c92-bb69-387a1094b57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 447])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9449ce8d-e9d7-4d88-853c-7bb4ab9eeddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 35, 51865])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9490ee8f-5005-4bdf-b093-2f9230b46041",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = func.softmax(logits, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5af90396-00d1-4b24-bfb0-e30e8d68b0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 35, 51865])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0605a42d-76d3-4c16-aa20-2895be60f6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5abc6cc-17b5-4da2-91ce-7ee4d2139d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|de|><|endoftext|><|endoftext|><|cy|>?.???? a.a to..�..pe....... by t le...<|endoftext|>.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.batch_decode(topk_indices.view(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db50417f-ae99-4df0-8b7e-823ea70fb4c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "prob_dist must be 1 or 2 dim",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m topk_probs, topk_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(probs, \u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopk_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m xcol \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(topk_indices, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, ix)\n\u001b[1;32m      4\u001b[0m processor\u001b[38;5;241m.\u001b[39mdecode(xcol\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: prob_dist must be 1 or 2 dim"
     ]
    }
   ],
   "source": [
    "topk_probs, topk_indices = torch.topk(probs, 1, dim=-1)\n",
    "ix = torch.multinomial(topk_probs, 1)\n",
    "xcol = torch.gather(topk_indices, -1, ix)\n",
    "processor.decode(xcol.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9c03a-1308-42c9-b8d3-42bba1752fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_probs, topk_indices = torch.topk(probs, 1, dim=-1)\n",
    "probs = func.softmax(logits, dim=-1)\n",
    "idx_next = torch.multinomial(probs, num_samples=1)\n",
    "if idx_next.item() == hf_model.config.eos_token_id:\n",
    "    break\n",
    "idx = torch.cat((idx, idx_next), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8bf191a-dff3-4521-bcdd-0f208d98a755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Die von der Kommission vorläufig veröffentlichten Zahlen weisen ebenfalls in diese Richtung.',\n",
       " 'bei der schilderung der ankunft des regierungsvertreters feierte er das martialische aussehen unsrer miliz die behenden dorfschönen die kahlköpfigen greise diese patriarchen die letzten der unsterblichen legionen deren soldatenherzen beim wirbeln',\n",
       " 'als sie den mann endlich versorgt sah übte die erworbenen geschicklichkeiten um sie nicht brach liegen zu lassen nun auch anderwärts aus und je älter sie wurde mit desto mehr einsicht und erfolg aber ohne glück für sie selber',\n",
       " 'Wir denken darüber nach.',\n",
       " 'er glaube seiner seele nicht daß er sein lebtag je hofrat werde es nehme ihn jetzt wunder wie es ihm mit dem papste gehe es hätten ihm nämlich zwei sonderbar vornehme herren von rom',\n",
       " 'auch dort hatten sich einige vorübergehende angesammelt auch dort wurde ein tamtam geschlagen sang man lieder verfluchte die sünde rief zur buße auf',\n",
       " 'sie wollte wirklich nach dem kloster gehen die priorin war ihre muhme der wollte sie alles sagen und sie um ihren rat bitten nur das war ihr unerträglich daß ihr liebster nicht wissen sollte wohin sie gekommen sie wußte wohl wie herzhaft er war und besorgt um sie',\n",
       " 'und neun blutige jahre durchkämpften wir söhne der griechen und im zehnten verheerten wir priamos türmende feste',\n",
       " 'Die Gerberstraße ist die wichtigste Ausfallstraße nach Norden.',\n",
       " 'Seine ersten Dramen wurden auf Russlands Bühnen große Erfolge.',\n",
       " 'Diese Triebwagen konnten zu Paaren gekoppelt werden, konnten aber keine anderen Wagen ziehen.',\n",
       " 'Wegen eines mechanischen Defekts fiel er in Großbritannien aus.',\n",
       " 'die wir schon früher auf des grafen wort gebaut und deshalb einen ziemlich beruhigten tag hingebracht hatten',\n",
       " 'Der Ort liegt im Norden des südbrandenburgischen Landkreises Oberspreewald-Lausitz.',\n",
       " 'Sie wurde benannt nach Paul Hamilton, dem vierten United States Secretary of the Navy.',\n",
       " 'sich die ziffer noch höher stellte der ackerbau ward in gallien wohl getrieben',\n",
       " 'Sie wird nach geographischen Kriterien zu den ägäischen Sprachen gezählt.',\n",
       " 'tannenbaum mit grünen fingern pocht ans niedre fensterlein und der mond der stille lauscher wirft sein goldnes licht',\n",
       " 'ohne den hingeworfenen fehdehandschuh aufzunehmen und was mich am meisten freut sie nimmt es alles für ernst wer denn nun wer die maywald deine rivalin und nun höre oder lies es selbst nein ich mag nicht ich liebe',\n",
       " 'ich wußte daß peggotty in mein zimmer kommen würde die sabbatstille tat uns beiden wohl sie setzte sich neben mich auf mein kleines bett nahm meine hand drückte sie von zeit zu zeit an ihre lippen und streichelte sie',\n",
       " 'Die beiden hatten einen Sohn, Bernard Pagel.',\n",
       " 'wenn auch nicht in religiosem sinne wir haben das unabweichliche täglich zu erneuernde grundernstliche bestreben',\n",
       " 'zum büchsenstein zum türken zum meerwunder zum goldnen drachen zur linde zum pilgerstab zur wasserfrau zum paradiesvogel zum granatbaum zum kämbel zum einhorn und dergleichen',\n",
       " 'Anschließend wurden die Senatoren gewählt.',\n",
       " 'Warum wird eine Verbesserung dieser Ergebnisse empfohlen?',\n",
       " 'betreten worden ist die gelindeste wäre wohl ihn anzuspritzen und in einen hasen zu verwandeln',\n",
       " 'lange hatten sie an der nordküste von spitzbergen auf das eintreten des südwinds gewartet schon neigte sich der polarsommer seinem ende zu und sie fürchteten unverrichteter sache umkehren zu müssen wie der kühne schwede andre bei seinem ersten versuche',\n",
       " 'ich nahm anstand mich auszusprechen sie können reden sprach der kapitän dieser mann versteht nicht französisch ich sah den verwundeten nochmals an dann sprach ich binnen zwei stunden wird der mann sterben',\n",
       " 'ihr kennt es das harte leid heißt es entsagen mitzuwirken im sturm der zeit zu neuem',\n",
       " 'Das Gebäude wird heute als Mehrfamilienhaus genutzt.',\n",
       " 'nun weiß ich warum vor einigen jahren deine ganze phantasie von mönchen klöstern einsiedlern heiligen erfüllt war ich merkte das aus dem briefe den du mir damals schriebst und in dem ein solch eigner mystischer ton herrschte',\n",
       " 'Davon waren zwei Milliarden Euro neue Gelder.',\n",
       " 'wie sie im hause herumrannte in ihrer abschiedsaufregung wie sie die zwei riesenkoffer mit allem möglichen für berthold vollfüllte wie sie ihm noch einmal alle leckerbissen vorsetzte',\n",
       " 'Zuverlässige kommentierte Ausgaben stammen von',\n",
       " 'Sowohl El Hierro als auch La Gomera werden nahezu flächendeckend besiedelt.',\n",
       " 'mit diesen worten entließ mich der baron ich ging ich war vernichtet in meinem eignen innern herabgesunken zum bedeutungslosen törichten kinde',\n",
       " 'peterchen war sehr gerührt und anneliese wischte sich mit ihrem hemdzipfelchen sogar die augen weil ihr immer die tränen kamen dann aber faßte sich peterchen ein herz und sagte daß er das beinchen schon recht gern mit anneliese vom mond herunterholen möchte',\n",
       " 'Der nächste Sprecher ist Herr Fjellner.',\n",
       " 'nichts ist ärger mißhandelt worden in den vier kriegsjahren als der geist vernunft wurde unsinn und lüge höchste pflicht der geist mußte der erste rebell werden und das geschah zunächst schüchtern dann lauter und vehementer',\n",
       " 'Minute perfekt.',\n",
       " 'Die Lehre kann sowohl explizit als auch implizit enthalten sein.',\n",
       " 'fruehlingsanfang der erste monat desselben und der einzige der von einem gott den namen traegt heisst nach dem mars martius die drei folgenden vom sprossen aprilis wachsen',\n",
       " 'Diese Fragen erwiesen sich als die Hauptprobleme.',\n",
       " 'vielleicht erinnert man sich an das lebhafte tausendfache gewimmel von seltsamen geschöpfen die man unter dem mikroskop in einem tropfen sumpfigen wassers sich entwickeln sieht',\n",
       " 'Wir sind vielleicht in zweifacher Hinsicht gezwungen, aufzugeben.',\n",
       " 'er ergreift das schloß es singt inwendig meine mutter die hur die mich umgebracht hat mein vater der schelm der mich gessen hat mein schwesterlein klein hub auf die bein',\n",
       " 'und wie die frauen in allem recht haben so auch hierin es ist das traurigste von der welt immer wieder eine durchschnittsheldengeschichte von zweifelhaftem wert und noch zweifelhafterer wahrheit hören zu müssen',\n",
       " 'der weg dazu aber war sehr sonderbar der knabe hatte sich überhaupt an den ersten glaubensartikel gehalten',\n",
       " 'Grund hierfür war seine geringe Einsatzzeit.',\n",
       " 'zwischen sechs und sieben brachen die beiden frauenzimmer auf jeder versuch sie länger dazubehalten war fruchtlos frau von p und die mutter',\n",
       " 'das kreischen und lachen um falk herum wurde lauter und unerträglicher er erhob sich wütend und brüllte förmlich still dann setzte er sich hin die verfluchten mücken die ihn immer stören mußten nun wurde er sehr unruhig',\n",
       " 'Über den Minnesota River ist er Teil des Einzugsgebietes des Mississippi River.',\n",
       " 'Das Fahrzeugdeck ist zu etwa zwei Drittel der Schiffslänge mit den Decksaufbauten überbaut.',\n",
       " 'In China war diese Darstellungsweise jedoch schon weitaus früher bekannt.',\n",
       " 'Die Addition von Wasserstoff wird auch als Hydrierung bezeichnet.',\n",
       " 'Teilweise sind diese Häuser durch Verkauf in private Hand zu Einfamilien- oder Wochenendhäusern geworden.',\n",
       " 'ach es war ja der anzug wie ich ihn an jenem verhängnisvollen hochzeittage trug der doppelgänger stand mir vor augen',\n",
       " 'darüber war kein zweifel möglich trotzdem ritten wir um ganz sicher zu gehen in das tal hinein und untersuchten dasselbe so weit nach hinten bis uns auch die dortigen spuren vollständig überzeugten daß es von den kiowas verlassen worden war',\n",
       " 'Das Album klingt experimenteller und abwechslungsreicher als ihr erstes Album.',\n",
       " 'jetzt sprang sie aber empor und rief himmel wie heiß ist es hier da sitzen wir wie die narren und lassen uns versengen komm mein lieber laß uns ins hohe korn sitzen',\n",
       " 'hätte sich nicht ein berühmter doctor meiner erbarmt so mußt ich sterben aus erkenntlichkeit wurd ich eine zeitlang seine mätresse',\n",
       " 'in der morgensonne sich ausbreiten und zu einer der schönsten städte die von griechen bewohnt werden emporblühen sehe',\n",
       " 'Die Anregung zu dieser Arbeit stammte von Friedrich Schur; Gerhard Hessenberg gab Unterstützung.',\n",
       " 'daran erinnerte die kinder die immerfort von den zu erwartenden geschenken wisperten ihre ältere schwester luise hinzufügend',\n",
       " 'es wäre für eine kräftigere regierung als die damalige römische es war keine leichte aufgabe gewesen gegen diese weiten und barbarischen gebiete eine geordnete und ausreichende',\n",
       " 'amphinomos war ein braver jüngling bei weitem der beste unter den freiern darum zog ihn jetzt odysseus gutmütig näher und sagte zu ihm mit sanfter rede',\n",
       " 'mit seinem ganzen vermögen seinem sohn und dem volk und räumen eine der städte welche sparta umgrenzen und meinem befehle gehorchen',\n",
       " 'er und seine freunde liefen ihm entgegen da sprangen von den rossen fünfhundert schnelle degen wohl empfangen wurden die von heunenland niemals trugen boten wohl so herrlich gewand',\n",
       " 'leben und handwerk des kriegers wurden als mittel neuer aufzucht gepriesen jetzt steht der altar des ares schon lange ohne schmuck das resolute spartanertum unseres bundesfreundes verweyen wirkt an der schwelle des fünften kriegsjahres reichlich anachronistisch',\n",
       " 'Ein heute denkmalgeschützter Schornstein auf dem Steinberg erinnert an diese Zeit.',\n",
       " 'und den übrigen um dort mich selbst auf der tat zu ergreifen als unwissender denn sie von ihren gedichten also',\n",
       " 'Die Unbeschuhten Karmelitinnen bilden daher den größten beschaulichen Frauenorden.',\n",
       " 'Im Mittelalter wurde auf der Gemarkung Reichenbachs Bergbau betrieben.',\n",
       " 'Ich hoffe, dass in Zukunft mehr getan wird!',\n",
       " 'Das war sehr eindeutig.',\n",
       " 'Die notwendigen Entwicklungen sind in der Literatur zu finden.',\n",
       " 'Das geschieht auch gegenwärtig in der Europäischen Union.',\n",
       " 'Feldartillerieregiment und absolvierte die Kriegsschule.',\n",
       " 'es war mir zu enge dort und unwohl die mutter war was hoffärtigen mädchen gerne geschieht eine hotsch geworden das stübchen lüftete sie nicht räumte nicht auf sie selbst war entweder unvernünftig geputzt oder eine schlampe',\n",
       " 'in heftigem zorn geht in die hölle was hängt ihr euch gleich einem bösen geist an meine fersen fort ich kenn euch nicht ich habe nichts gemein mit',\n",
       " 'Durch den weitverbreiteten Gebrauch von Fluoriden beobachtet man heutzutage das Phänomen der „verborgenen Karies“.',\n",
       " 'Alle Pierer Vereine gehören der Dorfgemeinschaft Pierer Vereine an.',\n",
       " 'Gelegentlich kann dies, insbesondere vom heutigen Wissensstand, merkwürdig auffallen.',\n",
       " 'Diese Teams blieben darauf ohne Einkommen und Mitspracherecht.',\n",
       " 'Er wirkte danach als Lehrer in seiner Geburtsstadt Köslin.',\n",
       " 'dann die lefzen schnappte nach ihm ohne ihn zu fassen wiederholte diese prozedur mehrmals begann zu spielen legte sich das tier zwischen den pfoten und setzte seine untersuchungen fort wurde bald müde gleichgültig und vergaß schließlich sein spielzeug',\n",
       " 'Das Interesse der Bevölkerung war immer gegenwärtig.',\n",
       " 'Sie steht nicht auf der Agenda des Rates.',\n",
       " 'In Algerien war er an der Niederwerfung des Aufstands von Abd el-Kader beteiligt.',\n",
       " 'zwanzig eileten schnell zum wasser der schattichten quelle und die andern im saale vollendeten klüglich die arbeit',\n",
       " 'Drittens geht es offenkundig darum, die Behandlung solcher Streitfälle maximal zu erleichtern.',\n",
       " 'Im folgenden Jahr war sie ebenfalls Finalistin für den Preis.',\n",
       " 'Diese zweite Mitteilung werden wir Ihnen sicherlich in Kürze vorzulegen in der Lage sein.',\n",
       " 'Er wurde von den Kritikern positiv aufgenommen.',\n",
       " 'über die petition her faßte sie ab schrieb sie auf einen ungeheuern bogen papier breitete sie auf dem tisch aus und setzte die zeit fest wo der ganze klub und alle gefangenen',\n",
       " 'drittes buch erstes kapitel',\n",
       " 'seines glaubens an orakel träume und opferlebern antisthenes seiner geringschätzung aller gemächlichkeiten und künstlichen wollüste der reichen',\n",
       " 'verklaerung dem goettlichen dionysischen rausche den tiefsinnigen und geheimnisvollen',\n",
       " 'Auch ich danke all denen, die dieses Parlament im Konvent vertreten haben.',\n",
       " 'dann starb sie just als der kampf zu ende war und die guten tage kommen sollten auf die minute ausgerechnet just an dem tage wo die tochter erregt eintrat und der schwerkranken ihr gut bestandenes examen meldete schloß sie die müden augen zum langen schlaf',\n",
       " 'Sie ertönen tagsüber viertelstündlich zum Uhrschlag sowie im Rahmen der Läuteordnung.',\n",
       " 'Die inneren Blütenblätter sind gelb, die äußeren sind fast weiß.',\n",
       " 'Danach war der Verkauf zu Gunsten der Insel geplant.',\n",
       " 'In Richemont trägt eine Schule seinen Namen.',\n",
       " 'Sie wurde nur noch als Wohnschiff genutzt.',\n",
       " 'that verdiente läßt sich auf die edikte selbst ein schluß machen die schriftsteller der sekten hieß es darin ihre vorsteher und lehrer wie auch die welche',\n",
       " 'Nach dem Weggang von Lynne stießen Mike Hopkins und Dave Walker zur Band.',\n",
       " 'wollt ihrs nicht lassen sprach da dankwart so gereut mich meines flehens hätt ich das gespart der schnelle kühne degen von dem tische sprang eine scharfe waffe zog er die war gewaltig und lang',\n",
       " 'In Jahren mit Olympischen Winterspielen wird die Weltmeisterschaft nicht ausgetragen.',\n",
       " 'Der Wohnplatz liegt im südlichen Bereich der Gemarkung von Sperenberg.',\n",
       " 'Dort fand seine erste Begegnung mit dem Buddhismus statt.',\n",
       " 'Es erscheint jeweils am Donnerstag als Beilage des Tages-Anzeigers.',\n",
       " 'Vier Jahre später zieht er nach Thorn um dort Luftfahrttechnik zu studieren.',\n",
       " 'führe ihn herein sagte farkad einem seiner adjutanten da erschien ein alter mann der so ehrwürdig aussah daß farkad ihn freundlich aufnahm neben sich sitzen ließ und ihn in einem sanften ton fragte woher er komme wer er sei und welche botschaft er bringe',\n",
       " 'Brauneck gehörte zur Realgemeinde Harsdorf.',\n",
       " 'In beiden Fällen ist ein vollständiges Mithören aller über die Leitung übertragener Daten möglich.',\n",
       " 'Die genaue Entwicklung bis in die Gegenwart ist jedoch unbekannt.',\n",
       " 'Als Schüler schrieb er gerne Abenteuergeschichten.',\n",
       " 'der viehhof der obstgarten der gemüsegarten die wiesen und felder wurden in verschiedene abteilungen zerlegt und sollten getrennte betriebsgebiete bilden',\n",
       " 'Es gibt mehrere Varianten der Geschichte.',\n",
       " 'Er steht der Hafer-Pflaume nahe.',\n",
       " 'Gleichzeitig sinkt der Puls.',\n",
       " 'getrocknete pflanzen und insekten und manche arten von anatomischen präparaten menschenhaut knochen mumien und dergleichen kamen auf das krankenbette der kleinen',\n",
       " 'Anerkennung brachte ihm die Zusammenarbeit mit Roy Hargrove.',\n",
       " 'der brief des adjutanten enthielt diesen persönlichen befehl in dienstlicher fassung jetzt erst nachdem mein vater mir unrecht getan hatte empfand ich die ganze lächerliche tragik der ich unschuldig verfallen war',\n",
       " 'illo herr bruder hab ichs schon erzählt der fürst will meine kreditoren kontentieren will selber mein kassier sein künftighin',\n",
       " 'Die vier bestplatzierten Teams ermitteln in Halbfinalspielen die beiden Endspielteilnehmer.',\n",
       " 'Die abgekürzte Version war Handelsministerium.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28352205-c3a6-4659-b4bf-f140a1f00478",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "hf_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc28f36-6c80-48ee-9218-94eb7d7b0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_start_token_id = hf_model.config.decoder_start_token_id  # <|startoftranscript|>\n",
    "decoder_prev_token_id = tokenizer.all_special_ids[-3]  # <|startofprev|>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7bdfd5c-401f-40a8-a8f1-2db2a4e9e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ds = load_from_disk('/Users/xinzheng/workspace/chenlong/services/asr_small/one_batch.hf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395e9792-f165-4e5b-8256-4c0efe115502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'text', 'input_features', 'input_length', 'labels'],\n",
       "    num_rows: 128\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2d51f8-d593-48d4-81ad-03e7e889fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor ([`Wav2Vec2Processor`])\n",
    "            The processor used for proccessing the data.\n",
    "        decoder_start_token_id (:obj: `int`)\n",
    "            The start-of-sequence token id of the decoder.\n",
    "        decoder_prev_token_id (:obj: `int`)\n",
    "            The start-of-prompt token id of the decoder\n",
    "        input_padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned input sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        target_padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned target sequences (according to the model's padding side and padding index).\n",
    "            See above for details.\n",
    "        max_target_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` of the returned list and optionally padding length (see above).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "    decoder_prev_token_id: int\n",
    "    input_padding: Union[bool, str] = \"max_length\"\n",
    "    target_padding: Union[bool, str] = \"max_length\"\n",
    "    max_target_length: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], np.ndarray]]]) -> Dict[str, np.ndarray]:\n",
    "        # split inputs and labels since they have to be of different lengths and need\n",
    "        # different padding methods\n",
    "\n",
    "        # dataloader returns a list of features which we convert to a dict\n",
    "        input_features = {\"input_features\": [feature[\"input_features\"] for feature in features]}\n",
    "        label_features = {\"input_ids\": [feature[\"labels\"] for feature in features]}\n",
    "\n",
    "        # reformat list to dict and set to pytorch format\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            input_features,\n",
    "            padding=self.input_padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            label_features,\n",
    "            max_length=self.max_target_length,\n",
    "            padding=self.target_padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # shift labels to the right to get decoder input ids\n",
    "        labels = labels_batch[\"input_ids\"]\n",
    "        decoder_input_ids = labels[:, :-1]\n",
    "        labels = labels[:, 1:]\n",
    "        labels_mask = labels_batch.attention_mask[:, 1:]\n",
    "\n",
    "        # replace padding with -100 to ignore correctly when computing the loss\n",
    "        labels = labels.masked_fill(labels_mask.ne(1), -100)\n",
    "\n",
    "        # replace initial prompt tokens with -100 to ignore correctly when computing the loss\n",
    "        bos_index = torch.argmax((labels == self.decoder_start_token_id).long(), dim=1)\n",
    "        bos_index = torch.where(bos_index > 0, bos_index + 1, bos_index)\n",
    "        prompt_mask = torch.arange(labels.shape[1]) < bos_index[:, None]\n",
    "        labels = torch.where(prompt_mask, -100, labels)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        batch[\"decoder_input_ids\"] = decoder_input_ids\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c35f612-bc21-49ac-8c01-05af95de5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "            processor=processor,\n",
    "            decoder_start_token_id=decoder_start_token_id,\n",
    "            decoder_prev_token_id=decoder_prev_token_id,\n",
    "            input_padding=\"longest\",\n",
    "            target_padding=\"max_length\",\n",
    "            max_target_length=448,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05985ea5-2783-45f3-af62-246673614ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "                small_ds,\n",
    "                collate_fn=data_collator,\n",
    "                batch_size=128,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc2b5d2-b9bb-4c92-82aa-97a9c42e994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinzheng/miniconda3/envs/asr/lib/python3.11/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = SmallWhisper(SmallWhisperConfig).from_pretrained('small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b13af94-f8a6-4871-9ab8-a0f266d1f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora.mark_only_lora_as_trainable(model, bias='lora_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252df8b3-4e71-471e-8973-8b957109ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(optim_groups, lr=3e-4, betas=betas, fused=use_fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994c242-05da-4f76-9deb-e722c5f045bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4278057c-2b6c-4868-9f96-099224c6849a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b596dc-cd4d-4dc8-a1b4-56df86bf0d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
